{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xm0fmhby4nEz",
        "outputId": "9718f636-7f57-464a-9f75-db2fe470c7f8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hFound existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl (176.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m176.0/176.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.13.3 torch-2.7.0+cpu torchaudio-2.7.0+cpu torchvision-0.22.0+cpu\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% Complete"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% CompleteIt looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://6775b974691a6e381a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://6775b974691a6e381a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Fix: Overwritten grand total 233.60 ‚Üí 28.60\n",
            "Final Fix: Overwritten grand total 28.60 ‚Üí 23.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 840, in __call__\n",
            "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 856, in simple_response\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 714, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 734, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 288, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 76, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 73, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 301, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 1580, in upload_file\n",
            "    form = await multipart_parser.parse()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 694, in parse\n",
            "    async for chunk in self.stream:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/requests.py\", line 235, in stream\n",
            "    raise ClientDisconnect()\n",
            "starlette.requests.ClientDisconnect\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Fix: Overwritten grand total 233.60 ‚Üí 28.60\n",
            "Final Fix: Overwritten grand total 28.60 ‚Üí 23.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://6775b974691a6e381a.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install gradio easyocr pandas matplotlib -q\n",
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "import gradio as gr\n",
        "import easyocr\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "def extract_store_name(ocr_lines):\n",
        "    lines_cleaned = [line.strip().lower() for line in ocr_lines if line.strip()]\n",
        "    full_combined = \" \".join(lines_cleaned)\n",
        "    blacklist = ['registration', 'co.reg', 'hypermall', 'plt', 'lot', 'ground floor', 'invoice']\n",
        "\n",
        "    brand_keywords = {\n",
        "        'ai-cha': 'AI-CHA', 'kiss my bowl': 'KISS MY BOWL', 'mr.diy': 'MR. D.I.Y',\n",
        "        'mr d.i.y': 'MR. D.I.Y', 'mr diy': 'MR. D.I.Y', 'guardian': 'GUARDIAN',\n",
        "        'padini': 'PADINI', 'watsons': 'WATSONS', 'parkson': 'PARKSON',\n",
        "        'everrise': 'EVERRISE', 'teppanya': 'TEPPANYA CAFE', 'marks & spencer': 'MARKS & SPENCER',\n",
        "        'cck': 'CCK FRESH MART', 'ccklocal': 'CCKLOCAL - KK', 'popular': 'POPULAR BOOKSTORE',\n",
        "        'h&m': 'H&M', 'h & m': 'H&M', 'hem': 'H&M', 'daiso': 'DAISO JAPAN', 'kfc': 'KFC',\n",
        "        '15 minutes bake': '15 MINUTES BAKE CAFE', 'uniqlo': 'UNIQLO', 'ilaollao': 'LLAOLLAO',\n",
        "        'llaollao': 'LLAOLLAO', 'caring': 'CARING PHARMACY', 'sushihan': 'SUSHIHAN',\n",
        "        'u$h|han': 'SUSHIHAN', 'u $ h | h a n': 'SUSHIHAN', 'tea co': 'TEA CO.', 'teaco': 'TEA CO.'\n",
        "    }\n",
        "\n",
        "    for keyword, brand in brand_keywords.items():\n",
        "        if keyword.replace(\" \", \"\").replace(\".\", \"\") in full_combined.replace(\" \", \"\").replace(\".\", \"\"):\n",
        "            return brand\n",
        "\n",
        "    for i, line in enumerate(lines_cleaned[:5]):\n",
        "        if i != 0 and any(bad in line for bad in blacklist): continue\n",
        "        if not any(char.isdigit() for char in line) and len(line) >= 5:\n",
        "            return line.title()\n",
        "    return None\n",
        "\n",
        "def extract_receipt(image_path):\n",
        "    results = reader.readtext(image_path)\n",
        "    ocr_texts = [text.lower() for (_, text, _) in results]\n",
        "    ocr_lines_raw = [text.strip() for (_, text, _) in results]\n",
        "\n",
        "    grand_total_amount = None\n",
        "    total_candidates = []\n",
        "\n",
        "    lines = [line.strip().lower().replace(\" \", \"\") for line in ocr_lines_raw]\n",
        "    exclude_keywords = ['saving', 'cash', 'change', 'points', 'qty', 'subtotal', 'item', 'unit', 'original', 'price', 'discount']\n",
        "    include_keywords = ['total', 'grand total', 'total amount', 'amount due']\n",
        "    total_keywords = ['grandtotal', 'total', 'totalamount', 'amountdue']\n",
        "\n",
        "    for i in range(len(lines) - 2):\n",
        "        line1 = lines[i]\n",
        "        line2 = lines[i + 1]\n",
        "        line3 = lines[i + 2]\n",
        "        combined = line1 + line2\n",
        "\n",
        "        if any(k in combined for k in total_keywords) and not any(b in combined for b in exclude_keywords):\n",
        "            if re.match(r'^[rm]*\\d{1,5}[.,]\\d{2}$', line3):\n",
        "                try:\n",
        "                    value = float(re.findall(r'[\\d.,]+', line3)[0].replace(\",\", \".\"))\n",
        "                    if 0.5 <= value <= 1000:\n",
        "                        total_candidates.append((i + 2, value))\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    for i in range(len(lines) - 1):\n",
        "        current = lines[i]\n",
        "        next_line = lines[i + 1]\n",
        "\n",
        "        if any(k in current for k in total_keywords) and not any(b in current for b in exclude_keywords):\n",
        "            if re.match(r'^[rm\\s]*\\d{1,5}[.,]\\d{2}$', next_line):\n",
        "                try:\n",
        "                    value = float(next_line.replace(\"rm\", \"\").replace(\",\", \".\").strip())\n",
        "                    if 0.5 <= value <= 1000:\n",
        "                        total_candidates.append((i + 1, value))\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            inline_match = re.search(r'(total|amount due)[:\\s]*rm?\\s*([\\d.,]+)', current)\n",
        "            if inline_match:\n",
        "                try:\n",
        "                    value = float(inline_match.group(2).replace(\",\", \".\"))\n",
        "                    if 0.5 <= value <= 1000:\n",
        "                        total_candidates.append((i, value))\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if re.match(r'^[rm\\s]*\\d{1,5}[.,]\\d{2}$', current) and any(k in next_line for k in total_keywords):\n",
        "                if not any(b in next_line for b in exclude_keywords):\n",
        "                    try:\n",
        "                        value = float(current.replace(\"rm\", \"\").replace(\",\", \".\").strip())\n",
        "                        if 0.5 <= value <= 1000:\n",
        "                            total_candidates.append((i, value))\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "    if total_candidates:\n",
        "        total_candidates.sort(key=lambda x: x[0], reverse=True)\n",
        "        grand_total_amount = total_candidates[0][1]\n",
        "\n",
        "    amounts = []\n",
        "\n",
        "    for i, (_, text, _) in enumerate(results):\n",
        "        lower = text.lower().strip()\n",
        "        if any(x in lower for x in exclude_keywords):\n",
        "            continue\n",
        "\n",
        "        if any(k in lower for k in include_keywords) and not any(x in lower for x in exclude_keywords):\n",
        "            found = re.findall(r'\\d{1,5}[.,]\\d{2}', text)\n",
        "            if not found and i + 1 < len(results):\n",
        "                next_text = results[i + 1][1]\n",
        "                found = re.findall(r'\\d{1,5}[.,]\\d{2}', next_text)\n",
        "            for f in found:\n",
        "                try:\n",
        "                    value = float(f.replace(\",\", \".\").replace(\" \", \"\"))\n",
        "                    if 0.5 <= value <= 1000:\n",
        "                        grand_total_amount = value\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        if grand_total_amount:\n",
        "            break\n",
        "\n",
        "    for i in range(len(results) - 1):\n",
        "        line = results[i][1].lower()\n",
        "        if 'total' in line and i + 2 < len(results):\n",
        "            num1 = results[i+1][1].strip().replace(\",\", \".\")\n",
        "            num2 = results[i+2][1].strip().replace(\",\", \".\")\n",
        "            if re.match(r'^\\d{1,3}$', num1) and re.match(r'^\\d{2}$', num2):\n",
        "                try:\n",
        "                    combined = float(f\"{int(num1)}.{int(num2)}\")\n",
        "                    if 0.5 <= combined <= 500:\n",
        "                        grand_total_amount = combined\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    if not grand_total_amount:\n",
        "        for (_, text, _) in results:\n",
        "            if any(x in text.lower() for x in exclude_keywords):\n",
        "                continue\n",
        "            found = re.findall(r'\\d{1,5}[.,]\\d{2}', text)\n",
        "            for f in found:\n",
        "                try:\n",
        "                    value = float(f.replace(\",\", \".\"))\n",
        "                    if 0.5 <= value <= 1000:\n",
        "                        amounts.append(value)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    if not grand_total_amount and amounts:\n",
        "        grand_total_amount = max(amounts)\n",
        "\n",
        "    if not grand_total_amount:\n",
        "        for i in range(len(results) - 1):\n",
        "            current = results[i][1].lower().strip()\n",
        "            next_line = results[i + 1][1].strip()\n",
        "\n",
        "            if any(x in current for x in exclude_keywords):\n",
        "                continue\n",
        "\n",
        "            if re.match(r'^rm$', current) and re.match(r'^\\d{1,5}(\\.\\d{1,2})?$', next_line):\n",
        "                try:\n",
        "                    value = float(next_line)\n",
        "                    if 0.5 <= value <= 1000:\n",
        "                        grand_total_amount = value\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if re.match(r'^\\d{1,5}(\\.\\d{1,2})?$', current) and re.match(r'^rm$', next_line.lower()):\n",
        "                try:\n",
        "                    value = float(current)\n",
        "                    if 0.5 <= value <= 1000:\n",
        "                        grand_total_amount = value\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    if grand_total_amount and grand_total_amount > 100:\n",
        "        for i in range(len(ocr_lines_raw) - 1):\n",
        "            line = ocr_lines_raw[i].lower()\n",
        "            if \"sub\" in line and \"total\" in line:\n",
        "                try:\n",
        "                    suspicious_value = float(ocr_lines_raw[i + 1].replace(\",\", \".\").replace(\"rm\", \"\").replace(\"rl\", \"\").strip())\n",
        "                    if suspicious_value > 100:\n",
        "                        for j in range(i + 2, len(ocr_lines_raw)):\n",
        "                            next_line = ocr_lines_raw[j].lower()\n",
        "                            next_matches = re.findall(r'\\d{1,5}[.,]\\d{2}', next_line)\n",
        "                            for match in next_matches:\n",
        "                                try:\n",
        "                                    corrected = float(match.replace(\",\", \".\"))\n",
        "                                    if 0.5 <= corrected <= 100:\n",
        "                                        print(f\"Final Fix: Overwritten grand total {grand_total_amount:.2f} ‚Üí {corrected:.2f}\")\n",
        "                                        grand_total_amount = corrected\n",
        "                                        break\n",
        "                                except:\n",
        "                                    continue\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    date_found = None\n",
        "    for line in ocr_texts:\n",
        "        if 'date' in line:\n",
        "            match = re.search(r'(\\d{4})[/-](\\d{1,2})[/-](\\d{1,2})', line)\n",
        "            if not match:\n",
        "                match = re.search(r'(\\d{1,2})[/-](\\d{1,2})[/-](\\d{4})', line)\n",
        "            if match:\n",
        "                y, m, d = match.groups() if len(match.groups()[0]) == 4 else (match.groups()[2], match.groups()[1], match.groups()[0])\n",
        "                try:\n",
        "                    year = int(y)\n",
        "                    if 2000 <= year <= datetime.now().year + 2:\n",
        "                        date_found = f\"{year:04d}-{int(m):02d}-{int(d):02d}\"\n",
        "                        break\n",
        "                    elif 2195 <= year <= 2210:\n",
        "                        date_found = f\"2025-{int(m):02d}-{int(d):02d}\"\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    if not date_found:\n",
        "        for line in ocr_texts:\n",
        "            match = re.search(r'(\\d{1,2})[/-](\\d{1,2})[/-](\\d{2,4})', line)\n",
        "            if match:\n",
        "                d, m, y = match.groups()\n",
        "                if len(y) == 2:\n",
        "                    y = '20' + y\n",
        "                try:\n",
        "                    year = int(y)\n",
        "                    if 2000 <= year <= datetime.now().year + 2:\n",
        "                        date_found = f\"{year:04d}-{int(m):02d}-{int(d):02d}\"\n",
        "                        break\n",
        "                    elif 2195 <= year <= 2210:\n",
        "                        date_found = f\"2025-{int(m):02d}-{int(d):02d}\"\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    if not date_found:\n",
        "      for line in ocr_texts:\n",
        "        match = re.search(r'(\\d{1,2})[/-](Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[/-](\\d{2,4})', line, re.IGNORECASE)\n",
        "        if match:\n",
        "            d, mon, y = match.groups()\n",
        "            mon_map = {\n",
        "                'jan': '01', 'feb': '02', 'mar': '03', 'apr': '04', 'may': '05', 'jun': '06',\n",
        "                'jul': '07', 'aug': '08', 'sep': '09', 'oct': '10', 'nov': '11', 'dec': '12'\n",
        "            }\n",
        "            mon_num = mon_map.get(mon[:3].lower())\n",
        "            if mon_num:\n",
        "                if len(y) == 2:\n",
        "                    y = '20' + y\n",
        "                try:\n",
        "                    date_found = f\"{int(y):04d}-{mon_num}-{int(d):02d}\"\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    store_name = extract_store_name(ocr_lines_raw)\n",
        "    if store_name:\n",
        "        store_name = store_name.upper()\n",
        "        if any(bad in store_name for bad in ['D. .Y', 'D .Y', 'MR D', 'MR. D']):\n",
        "            store_name = 'MR. D.I.Y'\n",
        "        elif 'DIY' in store_name.replace(\" \", \"\"):\n",
        "            store_name = 'MR. D.I.Y'\n",
        "        store_name = (store_name.replace('(EN)', '(EM)')\n",
        "                                 .replace('(En)', '(EM)')\n",
        "                                 .replace('SDN,BHD', 'SDN. BHD')\n",
        "                                 .replace('SDN.BHD.', 'SDN. BHD')\n",
        "                                 .replace('BHD_', 'BHD'))\n",
        "        if 'SDN' in store_name and 'BHD' not in store_name:\n",
        "            store_name += ' BHD'\n",
        "    return store_name or \"\", date_found or \"\", f\"{grand_total_amount:.2f}\" if grand_total_amount else \"\"\n",
        "\n",
        "def save_record(name, date, amount):\n",
        "    try:\n",
        "        parsed_date = pd.to_datetime(date, format='%d/%m/%Y', errors='coerce')\n",
        "        if pd.isna(parsed_date):\n",
        "            parsed_date = pd.to_datetime(date, format='%Y-%m-%d', errors='coerce')\n",
        "        if not pd.isna(parsed_date):\n",
        "            date = parsed_date.strftime('%Y-%m-%d')\n",
        "    except:\n",
        "        pass\n",
        "    csv_path = \"/content/receipt_records.csv\"\n",
        "    if os.path.exists(csv_path):\n",
        "        df = pd.read_csv(csv_path)\n",
        "    else:\n",
        "        df = pd.DataFrame(columns=[\"Store Name\", \"Date\", \"Amount (RM)\"])\n",
        "    new_entry = {\"Store Name\": name, \"Date\": date, \"Amount (RM)\": f\"{float(amount):.2f}\" if amount else \"\"}\n",
        "    df = pd.concat([df, pd.DataFrame([new_entry])], ignore_index=True)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    return \"‚úÖ Record saved successfully!\"\n",
        "\n",
        "def load_records():\n",
        "    path = \"/content/receipt_records.csv\"\n",
        "    if os.path.exists(path):\n",
        "        df = pd.read_csv(path)\n",
        "        df = df.loc[:, ~df.columns.str.lower().isin([\"index\", \"unnamed: 0\", \"Index\", \"Index.1\"])]\n",
        "        df[\"Date\"] = df[\"Date\"].astype(str).str.strip()\n",
        "        df[\"Amount (RM)\"] = pd.to_numeric(df[\"Amount (RM)\"], errors=\"coerce\").map(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"\")\n",
        "        df.insert(0, \"Index\", range(len(df)))\n",
        "        return df\n",
        "    return pd.DataFrame(columns=[\"Index\", \"Store Name\", \"Date\", \"Amount (RM)\"])\n",
        "\n",
        "def delete_record(index_to_delete):\n",
        "    df = load_records()\n",
        "    if 0 <= index_to_delete < len(df):\n",
        "        df = df.drop(index=index_to_delete).reset_index(drop=True)\n",
        "        df.to_csv(\"/content/receipt_records.csv\", index=False)\n",
        "    return load_records()\n",
        "\n",
        "def analyze_summary():\n",
        "    df = load_records()\n",
        "    if df.empty:\n",
        "        return \"‚ö†Ô∏è No data available for analysis\"\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True, errors='coerce')\n",
        "    df[\"Amount (RM)\"] = pd.to_numeric(df[\"Amount (RM)\"], errors='coerce')\n",
        "    total = df[\"Amount (RM)\"].sum()\n",
        "    avg = df[\"Amount (RM)\"].mean()\n",
        "    max_ = df[\"Amount (RM)\"].max()\n",
        "    min_ = df[\"Amount (RM)\"].min()\n",
        "    return f\"üìä Expense Summary\\n\\nüí∞ Total ExpenseÔºöRM {total:.2f}\\nüìâ Average SpendingÔºöRM {avg:.2f}\\nüî∫ Highest ExpenseÔºöRM {max_:.2f}\\nüîª Lowest ExpenseÔºöRM {min_:.2f}\"\n",
        "\n",
        "def analyze_monthly_table():\n",
        "    df = load_records()\n",
        "    if df.empty or \"Date\" not in df or \"Amount (RM)\" not in df:\n",
        "        return pd.DataFrame(columns=[\"Month\", \"Amount (RM)\"])\n",
        "\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
        "    df[\"Amount (RM)\"] = pd.to_numeric(df[\"Amount (RM)\"], errors='coerce')\n",
        "\n",
        "    df = df.dropna(subset=[\"Date\", \"Amount (RM)\"])\n",
        "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
        "    monthly = df.groupby(\"Month\")[\"Amount (RM)\"].sum().reset_index()\n",
        "    monthly[\"Month\"] = monthly[\"Month\"].astype(str)\n",
        "    monthly[\"Amount (RM)\"] = monthly[\"Amount (RM)\"].map(lambda x: f\"{x:.2f}\")\n",
        "    return monthly\n",
        "\n",
        "def analyze_monthly_plot():\n",
        "    df = load_records()\n",
        "    if df.empty or \"Date\" not in df or \"Amount (RM)\" not in df:\n",
        "        return None\n",
        "\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
        "    df[\"Amount (RM)\"] = pd.to_numeric(df[\"Amount (RM)\"], errors='coerce')\n",
        "    df = df.dropna(subset=[\"Date\", \"Amount (RM)\"])\n",
        "\n",
        "    df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")\n",
        "    monthly = df.groupby(\"Month\")[\"Amount (RM)\"].sum().reset_index()\n",
        "    monthly[\"Month\"] = monthly[\"Month\"].astype(str)\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(monthly[\"Month\"], monthly[\"Amount (RM)\"], marker='o')\n",
        "    plt.title(\"Monthly Expense Trend Chart\")\n",
        "    plt.xlabel(\"Month\")\n",
        "    plt.ylabel(\"Total Expenses (RM)\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    return plt\n",
        "\n",
        "with gr.Blocks(title=\"üßæ Personal Expense Management System\") as demo:\n",
        "      gr.Markdown(\"## üßæ Personal Expense Management System\")\n",
        "\n",
        "      with gr.Tab(\"üì∏ Upload and Recognize Receipt\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                image_input = gr.Image(type=\"filepath\", label=\"Upload Receipt Image\")\n",
        "                extract_btn = gr.Button(\"üì§ Extract Information\")\n",
        "            with gr.Column():\n",
        "                name = gr.Textbox(label=\"üè™ Store Name\")\n",
        "                date = gr.Textbox(label=\"üìÖ Date\")\n",
        "                amount = gr.Textbox(label=\"üí∞ Total Amount (RM)\")\n",
        "                save_btn = gr.Button(\"‚úÖ Confirm and Save Record\")\n",
        "                save_result = gr.Textbox(label=\"\", interactive=False)\n",
        "        extract_btn.click(fn=extract_receipt, inputs=image_input, outputs=[name, date, amount])\n",
        "        save_btn.click(fn=save_record, inputs=[name, date, amount], outputs=save_result)\n",
        "\n",
        "      with gr.Tab(\"üìú View Expense Records\"):\n",
        "          refresh_btn = gr.Button(\"üîÑ Refresh Records\")\n",
        "          record_table = gr.Dataframe(interactive=False)\n",
        "          with gr.Row():\n",
        "            delete_index = gr.Number(label=\"üóëÔ∏è Enter Row Index to Delete (starting from 0)\", precision=0)\n",
        "            delete_btn = gr.Button(\"Delete Selected Record\")\n",
        "            refresh_btn.click(fn=load_records, outputs=record_table)\n",
        "            delete_btn.click(fn=delete_record, inputs=delete_index, outputs=record_table)\n",
        "\n",
        "      with gr.Tab(\"üìÖ Monthly Expense Table\"):\n",
        "          monthly_table = gr.Dataframe(label=\"üìÖ Monthly Total Expenses\")\n",
        "          monthly_btn = gr.Button(\"üì• Generate Table\")\n",
        "          monthly_btn.click(fn=analyze_monthly_table, outputs=monthly_table)\n",
        "\n",
        "      with gr.Tab(\"üìà Monthly Expense Trend\"):\n",
        "          trend_plot = gr.Plot(label=\"üìà Monthly Expense Trend Chart\")\n",
        "          trend_btn = gr.Button(\"üìä Generate Chart\")\n",
        "          trend_btn.click(fn=analyze_monthly_plot, outputs=trend_plot)\n",
        "\n",
        "      with gr.Tab(\"üìä Expense Summary\"):\n",
        "            summary_box = gr.Textbox(lines=8, label=\"üìä Expense Summary\")\n",
        "            summary_btn = gr.Button(\"üîç Analyze All Records\")\n",
        "            summary_btn.click(fn=analyze_summary, outputs=summary_box)\n",
        "\n",
        "            image_input.change(\n",
        "                fn=lambda x: (\"\", \"\", \"\", \"\") if x is None else gr.update(),\n",
        "                inputs=image_input,\n",
        "                outputs=[name, date, amount, save_result]\n",
        "                )\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ]
}